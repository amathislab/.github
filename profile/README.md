# Welcome to the A. Mathis Group at EPFL! 

Broadly speaking, we work at the intersection of computational neuroscience and machine learning, aka *AI4(Neuro)Science*. Ultimately, we are interested in reverse engineering the algorithms of the brain, in order to figure out how the brain works and to build better artificial intelligence systems.  

Check out [group's website for more information](http://www.mathisgroup.org), and see our open source code below!

## Packages for behavioral analysis:

- [DeepLabCut](https://github.com/DeepLabCut/DeepLabCut): for animal pose estimation
- [DLC2action](https://github.com/AlexEMG/DLC2action): for action segmentation 

## Selected Code from published research projects üë©‚Äçüíª:

**Computer Vision and Behavioral Analysis:**

- [HOISDF: Constraining 3D Hand-Object Pose Estimation with Global Signed Distance Fields](https://amathislab.github.io/HOISDF/): Code for Haozhe Qi, Chen Zhao, Mathieu Salzmann, & Alexander Mathis. CVPR (in press) 2024
- [WildCLIP: Scene and animal attribute retrieval from camera trap data with domain-adapted vision-language models](https://github.com/amathislab/wildclip): Code for Gabeff, Russwurm, Tuia & Mathis BioRxiv 2023. International Journal of Computer Vision (in press)
- [Bottom-up conditioned top-down pose estimation (BUCTD)](https://github.com/amathislab/BUCTD): Code for Zhou*, Stoffl*, Mathis and Mathis ICCV 2023. State of the art code for performing 2D pose estimation in crowded scenes. 
- [End-to-end trainable multi-instance pose estimation with transformers](https://github.com/amathislab/poet): Code for POET model, Stoffl, Vidal & Mathis arxiv 2021
- [AcinoSet: A 3D Pose Estimation Dataset and Baseline Models for Cheetahs in the Wild](https://github.com/amathislab/AcinoSet), Joska et al. ICRA 2021
- [Primer on Motion Capture](https://github.com/amathislab/Primer-MotionCapture), Mathis et al. Neuron 2020

**Reinforcement learning (mostly for motor skills):**

- [Acquiring musculoskeletal skills with curriculum-based reinforcement learning](https://github.com/amathislab/myochallenge): Code for Chiappa, et al. BioRxiv 2024
- [Winning code for the object manipulation track of the MyoChallenge at NeurIPS 2023](https://github.com/amathislab/myochallenge-lattice), article forthcoming
- [Latent Exploration for Reinforcement Learning](https://github.com/amathislab/lattice): Code for Chiappa, et al. NeurIPS 2023 
- [DMAP: a Distributed Morphological Attention Policy for Learning to Locomote with a Changing Body](https://github.com/amathislab/dmap): Code for Chiappa, Marin-Vargas & Mathis NeurIPS 2022
- [Winning code for the Baoding ball MyoChallenge at NeurIPS 2022](https://github.com/amathislab/myochallenge), joint work with Pouget Lab (University of Geneva). Caggiano et al. Proceedings of Machine Learning Research 2022

**AI4Science including modeling sensorimotor control:**

- [Task-driven-proprioception](https://github.com/amathislab/Task-driven-Proprioception): Code for modeling the proprioceptive system of primates. Marin Vargas* & Bisi* et al. Cell (in press) 2024
- [ODEformer: symbolic regression of dynamical systems with transformers](https://github.com/sdascoli/odeformer): Code from d'Ascoli*, Becker*, Schwaller, Mathis & Kilbertus ICLR 2024 (spotlight). Cool code to infer symbolic formulas from data
- [DeepDraw](https://github.com/amathislab/DeepDraw): Code for modeling proprioception with task-driven modeling, Sanbrink*, Mamidanna* et al. eLife 2023


üåà Please reach out, if you want to work with us! We love collaborative, open-source science.

We often collaborate with the group of Mackenzie Mathis, and also [recommend checking out their GitHub repository!](https://github.com/AdaptiveMotorControlLab)
<!--

**Here are some ideas to get you started:**

üôã‚Äç‚ôÄÔ∏è A short introduction - what is your organization all about?
üåà Contribution guidelines - how can the community get involved?
üë©‚Äçüíª Useful resources - where can the community find your docs? Is there anything else the community should know?
üçø Fun facts - what does your team eat for breakfast?
üßô Remember, you can do mighty things with the power of [Markdown](https://docs.github.com/github/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax)
-->
